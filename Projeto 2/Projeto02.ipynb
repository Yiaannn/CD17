{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 13/Set até às 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "Até o dia 06 de Setembro às 23:59, o notebook e o xlsx devem estar no Github com as seguintes evidências: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste já classificado.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conexão com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "#%%capture\n",
    "#\n",
    "##Instalando o tweepy\n",
    "#!pip install tweepy\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que serão utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados é necessário ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: @PJ2_CD17\n",
    "\n",
    "\n",
    "1. Caso ainda não tenha uma: https://twitter.com/signup\n",
    "1. Depois é necessário registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote também:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATENÇÃO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele contém as chaves necessárias para realizar as operações no twitter de forma automática e portanto é equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as operações manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo não precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @PJ2_CD17\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, não haverá uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Drawing Tablet'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "#lang = 'pt'\n",
    "lang = 'en'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Cria um objeto para a captura\\napi = tweepy.API(auth)\\n\\n#Inicia a captura, para mais detalhes: ver a documentação do tweepy\\ni = 1\\nmsgs = []\\nfor msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \\n    msgs.append(msg.text.lower())\\n    i += 1\\n    if i > n:\\n        break\\n\\n#Embaralhando as mensagens para reduzir um possível viés\\nshuffle(msgs)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Verifica se o arquivo não existe para não substituir um conjunto pronto\\nif not os.path.isfile('./{0}.xlsx'.format(produto)):\\n    \\n    #Abre o arquivo para escrita\\n    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\\n\\n    #divide o conjunto de mensagens em duas planilhas\\n    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\\n    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\\n\\n    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\\n    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\\n\\n    #fecha o arquivo\\n    writer.save()\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora você deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem é relevante ou não.<br /> \n",
    "Não se esqueça de colocar um nome para a coluna na célula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu código abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavra</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Irrelevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>drawing</td>\n",
       "      <td>174</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>tablet</td>\n",
       "      <td>173</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>came</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>today</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>#art</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Palavra Relevante Irrelevante\n",
       "888  drawing       174          97\n",
       "887   tablet       173         100\n",
       "886     came         4           0\n",
       "885    today         6           1\n",
       "884     #art         4           1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar a planilha de excel em um formato python\n",
    "database= pd.read_excel(\"Drawing Tablet.xlsx\")\n",
    "wordbase= pd.DataFrame(columns=['Palavra', 'Relevante', 'Irrelevante'])\n",
    "\n",
    "# Ler as mensagens, tokenizando as palavras\n",
    "#--considerar só palavras com mais de 3 letras (excluir palavras como \"a\", \"of\", \"the\")\n",
    "#--remover palavras que sejam de outra forma não interessante\n",
    "# Contar quantas vezes minhas palavras chaves aparecem em tweets relevantes e tweets irrelevantes\n",
    "size= len(database[\"Treinamento\"])\n",
    "i=0\n",
    "while i!=size:\n",
    "    temp=[]\n",
    "    for word in database[\"Treinamento\"][i].split():\n",
    "        if ('@' in word):\n",
    "            continue #pular palavras que forem nicknames\n",
    "        word= word.strip()\n",
    "        if ('http' in word):\n",
    "            word='#website#' #considerar todos os endereços de rede como um item monolítico\n",
    "        word = re.sub(r'[^\\w\\s#]','',word) #tirar pontuações, mantendo hashtags\n",
    "        if word not in temp:\n",
    "            temp.append(word) #Assim desconsidero a mesma palavra multiplas vezes no mesmo tweet\n",
    "            if len(word)>3:\n",
    "                if (not (wordbase['Palavra'] == word).any()): #se a palavra for nova para meu dataframe...\n",
    "                    wordbase.loc[-1]= [word, 0, 0]\n",
    "                    wordbase.index= wordbase.index + 1\n",
    "                    \n",
    "                current= wordbase.loc[wordbase['Palavra'] == word].index\n",
    "                if database[\"Relevância\"][i]=='relevante':\n",
    "                    wordbase['Relevante'][current]+=1\n",
    "                if database[\"Relevância\"][i]=='irrelevante':\n",
    "                    wordbase['Irrelevante'][current]+=1\n",
    "                    \n",
    "    i+=1\n",
    "    \n",
    "# Excluir palavras com menos de 4 ocorrências (não é suficientemente interessante)\n",
    "wordbase = wordbase[wordbase['Relevante']+wordbase['Irrelevante'] >= 4]\n",
    "\n",
    "wordbase.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# Criar um novo arquivo excel com novos tweets, dessa vez categorizados pela máquina\n",
    "\n",
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "\n",
    "if not os.path.isfile('./{0}-Final.xlsx'.format(produto)):\n",
    "    \n",
    "    #Cria um objeto para a captura\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    #Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "    i = 1\n",
    "    msgs = []\n",
    "    for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "        msgs.append(msg.text.lower())\n",
    "        i += 1\n",
    "        if i > n:\n",
    "            break\n",
    "            \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('./{0}-Final.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    results = pd.DataFrame(columns=[\"Tweet\", \"Relevância\"])\n",
    "    \n",
    "    for tweet in msgs:\n",
    "        temp=[]\n",
    "        isrelevant=1.0\n",
    "        isirrelevant=1.0\n",
    "        for word in tweet.split():\n",
    "            if ('@' in word):\n",
    "                continue #pular palavras que forem nicknames\n",
    "            word= word.strip()\n",
    "            if ('http' in word):\n",
    "                word='#website#' #considerar todos os endereços de rede como um item monolítico\n",
    "            word = re.sub(r'[^\\w\\s#]','',word) #tirar pontuações, mantendo hashtags\n",
    "            if word not in temp:\n",
    "                temp.append(word) #Assim desconsidero a mesma palavra multiplas vezes no mesmo tweet\n",
    "                if len(word)>3:\n",
    "                    ### Este é o bloco em que de fato aplico meu algoritmo ###\n",
    "                    \n",
    "                    if ((wordbase['Palavra'] == word).any()): #se a palavra estiver de fato no meu dataframe...      \n",
    "                        current= wordbase.loc[wordbase['Palavra'] == word].index\n",
    "                        #probabilidade que a palavra seja relevante, aplicando laplace smoothing\n",
    "                        prob= int(wordbase['Relevante'][current] + 1)/float(wordbase['Relevante'][current] + wordbase['Irrelevante'][current] + len(wordbase['Palavra']))\n",
    "                        isrelevant*=prob\n",
    "                        prob= int(wordbase['Irrelevante'][current] + 1)/float(wordbase['Relevante'][current] + wordbase['Irrelevante'][current] + len(wordbase['Palavra']))\n",
    "                        isirrelevant*=prob\n",
    "                        \n",
    "                    ### Fim do bloco ###\n",
    "        word=\"irrelevante\"\n",
    "        if (isrelevant > isirrelevant):\n",
    "            word='relevante'\n",
    "        results.loc[-1]= [tweet, word]\n",
    "        results.index= results.index + 1\n",
    "    \n",
    "    results.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de Positivos Verdadeiros: 59.8%\n",
      "Porcentagem de Negativos Falsos 3.6%\n",
      "Porcentagem de Positivos Falsos 8.0%\n",
      "Porcentagem de Negativos Verdadeiros 28.6%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positivos Falsos</th>\n",
       "      <th>Positivos Verdadeiros</th>\n",
       "      <th>Negativos Verdadeiros</th>\n",
       "      <th>Negativos Falsos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>299</td>\n",
       "      <td>143</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Positivos Falsos Positivos Verdadeiros Negativos Verdadeiros  \\\n",
       "0               40                   299                   143   \n",
       "\n",
       "  Negativos Falsos  \n",
       "0               18  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comparar os resultados obtidos pelo algoritmo com a classificação dada por mim:\n",
    "\n",
    "# Carregar a planilha de excel em um formato python\n",
    "database= pd.read_excel(\"Drawing Tablet-Final.xlsx\")\n",
    "results= pd.DataFrame(columns=['Positivos Falsos', 'Positivos Verdadeiros', 'Negativos Verdadeiros', 'Negativos Falsos'])\n",
    "results.loc[-1]= [0, 0, 0, 0]\n",
    "results.index= results.index + 1\n",
    "\n",
    "# Ler as mensagens, tokenizando as palavras\n",
    "#--considerar só palavras com mais de 3 letras (excluir palavras como \"a\", \"of\", \"the\")\n",
    "#--remover palavras que sejam de outra forma não interessante\n",
    "# Contar quantas vezes minhas palavras chaves aparecem em tweets relevantes e tweets irrelevantes\n",
    "size= len(database[\"Tweet\"])\n",
    "i=0\n",
    "\n",
    "while i!=size:\n",
    "    \n",
    "    if(database[\"Relevância – Máquina\"][i]=='relevante' and database[\"Relevância – Humano\"][i]=='relevante'):\n",
    "        results['Positivos Verdadeiros'][0]+=1\n",
    "    elif(database[\"Relevância – Máquina\"][i]=='irrelevante' and database[\"Relevância – Humano\"][i]=='relevante'):\n",
    "        results['Negativos Falsos'][0]+=1\n",
    "    elif(database[\"Relevância – Máquina\"][i]=='relevante' and database[\"Relevância – Humano\"][i]=='irrelevante'):\n",
    "        results['Positivos Falsos'][0]+=1\n",
    "    elif(database[\"Relevância – Máquina\"][i]=='irrelevante' and database[\"Relevância – Humano\"][i]=='irrelevante'):\n",
    "        results['Negativos Verdadeiros'][0]+=1            \n",
    "    i+=1\n",
    "\n",
    "total= results['Positivos Verdadeiros'][0] + results['Negativos Falsos'][0] + results['Positivos Falsos'][0] + results['Negativos Verdadeiros']\n",
    "\n",
    "print('Porcentagem de Positivos Verdadeiros: '+str(100*results['Positivos Verdadeiros'][0]/float(total))+'%')\n",
    "print('Porcentagem de Negativos Falsos '+str(100*results['Negativos Falsos'][0]/float(total))+'%')\n",
    "print('Porcentagem de Positivos Falsos '+str(100*results['Positivos Falsos'][0]/float(total))+'%')\n",
    "print('Porcentagem de Negativos Verdadeiros '+str(100*results['Negativos Verdadeiros'][0]/float(total))+'%')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As medidas obtidas foram satisfatórias, com um sucesso de medidas de quase 90%. A principal força do algoritmo treinado pareceu ser, com uma faixa grande de sucesso, descartar tweets de spam comerciais,\n",
    "\n",
    "Um caminho possível a seguir para continuar a desenvolver o aplicativo é tratar retweets diferentemente de tweets originais. Pela natureza que tem esses tendem a cortar palavras, criar biases quanto a endereços de rede e a magnificar exageradamente certos tweets populares.\n",
    "\n",
    "Sarcasmo e dupla negação não foram tratados, felizmente as amostras analisadas na grande maioria não apresentaram essa espécie de linguagem.\n",
    "\n",
    "O algoritmo treinado infelizmente não pode se aprimorar por si só, a forma com que funciona requer que suas análises estatísticas das palavras utilizadas existam à priori da aplicão. Por isso é necessário o treinamento por meio da inclusão de uma análise feita por uma pessoa quanto a quais tweets são relevantes ou não\n",
    "\n",
    "O experimento mostra outras possibilidades para o algoritmo de Naive-Bayes, problemas formulados como uma questão de múltipla decisão baseada em sucesso e fracasso podem ser tratados com o algoritmo de Naive-Bayes, incluindo path-finding para AIs ou o aprendizado de jogos complexos como xadrez "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
